{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $$\\textbf{Quantum Kitchen Sinks}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pyquil import get_qc, Program\n",
    "\n",
    "from qks_utils import generate_frame\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following \"picture frames\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapts = 1000\n",
    "x_small, y_small = generate_frame(num_datapts, 2, 0.1)\n",
    "x_big, y_big = generate_frame(num_datapts, 4, 0.2)\n",
    "plt.scatter(x_small, y_small, color='blue')\n",
    "plt.scatter(x_big, y_big, color='red')\n",
    "plt.title(\"Picture frames data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No linear classifier, such as Logistic Regression, would be able to accurately classify the data above. This can be readily seen from the exercise below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the label '1' for the small (blue) picture frame,\n",
    "#      and the label '0' for the large (red) picture frame\n",
    "small_frame = np.column_stack([x_small, y_small, np.ones(num_datapts)])\n",
    "big_frame = np.column_stack([x_big, y_big, np.zeros(num_datapts)])\n",
    "picture_frames = np.row_stack([small_frame, big_frame])\n",
    "\n",
    "# split into training and testing sets\n",
    "feat_train, feat_test, label_train, label_test = train_test_split(\n",
    "            picture_frames[:, :2], picture_frames[:, 2], test_size=0.20)\n",
    "\n",
    "# fit a Logistic Regression model onto this data\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(feat_train, label_train)\n",
    "label_preds = model.predict(feat_test)\n",
    "\n",
    "# report the accuracy score obtained (on a scale of 0.0 - 1.0)\n",
    "# (see https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score)\n",
    "accuracy = accuracy_score(label_test, label_preds)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we get the answer right only about half of the time. Which is to be expected, since no matter what kind of line you draw as a decision boundary on the figure above, the best you'd be able to do is to classify about half of the datapoints correctly, while misclassifying the remaining half."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter **Quantum Kitchen Sinks**. Based on the ideas introduced in https://arxiv.org/abs/1806.08321, let us imagine that every data point $u_i = (x_i, y_i)$ in the \"picture frames\" dataset gets mapped to some parameters of a quantum circuit,<br>\n",
    "<br>\n",
    "$$ \\Phi\\, : u_i \\rightarrow \\theta_i$$\n",
    "<br>\n",
    "where the $\\theta_i$ could be e.g. the rotation angles of an $RX$ gate on some qubit.\n",
    "Furthermore, the map $\\Phi$ could depend on some random parameters $\\Omega$ and $\\beta$. To use a specific example, let us take<br>\n",
    "<br>\n",
    "$$\\Omega = \\begin{pmatrix} \\alpha_0 & 0 \\\\ 0 & \\alpha_1 \\end{pmatrix}$$\n",
    "<br>\n",
    "where each of the diagonal entries are drawn i.i.d. from the standard normal distribution $\\mathcal{N}(0, 1)$. Let us also draw $\\beta$ from the uniform distribution on the interval $[0, 2 \\pi]$, and transform each 2-dimensional datapoint $u_i$ into a 2-dimensional parameter $\\theta_i$ as<br>\n",
    "<br>\n",
    "$$\\theta_i = \\Omega \\cdot u_i + \\beta$$\n",
    "<br>\n",
    "In fact, for every data point $u_i$, let us calculate $E$ different $\\theta_i$'s for just as many different values of $\\Omega$ and $\\beta$, where $E$ prescribes the total no. of \"episodes\". We'll use the index $e$ to specify the various episodes, we modify the expression above to the more precise<br>\n",
    "<br>\n",
    "$$\\theta_{ie} = \\Omega_e \\cdot u_i + \\beta_e$$\n",
    "<br>\n",
    "Before we go any further, let's first create a function that draws all the random variables we need. We'll do this for an ansatz(an educated guess) where we need two rotation angles for rotations on two separate qubits, an ansatz we'll refer to as the \"2q ansatz\" for short. It is important that we draw the same set of random parameters for all the data points in a data set. (Notice how the datapoints $u_i$ do not carry the index $e$!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_parameters_2q_ansatz(dim_input=2, num_episodes=500):\n",
    "    \"\"\"\n",
    "    Returns two sets of random parameters:-\n",
    "\n",
    "    alphas: entries drawn from the standard normal distribution N(0,1)\n",
    "        with shape (dim_input, num_episodes)\n",
    "    betas: entries drawn the uniform distribution U[0,2*pi]\n",
    "        with shape (num_episodes, 2), since we have a 2q ansatz\n",
    "    \"\"\"\n",
    "    # draw the diagonal entries of Ω matrix, a 2x2 matrix for each episode\n",
    "    alphas = np.random.normal(0.0, 1.0, size=dim_input * num_episodes)\n",
    "    # draw the β's, a 2-dimensional vector for each episode\n",
    "    betas = np.random.uniform(low=0.0, high=2 * np.pi, size=dim_input * num_episodes).reshape(-1, 2) \n",
    "\n",
    "    return alphas, betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use these features to transform the squares of the \"picture frames\" dataset into the parameters $\\theta_{ie}$. We will further use these features as rotation angles in a quantum circuit using the ansatz shown below (generated using `pyquil.latex`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"qks_2q_ansatz.png\" alt=\"Drawing\" style=\"width: 200px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circuit_qc_2q():\n",
    "    \"\"\"\n",
    "    Circuit for the 2-qubit ansatz\n",
    "\n",
    "    :return: pyQuil Program corresponding to the 2-qubit ansatz\n",
    "    \"\"\"\n",
    "    program = Program(\"\"\"\n",
    "DECLARE theta0 REAL\n",
    "DECLARE theta1 REAL\n",
    "DECLARE ro BIT[2]\n",
    "\n",
    "RX(theta0) 0\n",
    "RX(theta1) 1\n",
    "CNOT 0 1\n",
    "\n",
    "MEASURE 0 ro[0]\n",
    "MEASURE 1 ro[1]\n",
    "\"\"\")\n",
    "    return program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we kept our circuit ansatz purely parameteric, i.e. we didn't specify values for either parameter `theta0` or `theta1`. Because of pyQuil's ability to perform parametric compilation, this saves us some overhead in running the ansatz above over a range of values for the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a helper function that will transform a datapoint into a set of rotation angles. As discussed earlier, this transformation is described as<br>\n",
    "<br>\n",
    "$$\\theta_{ie} = \\Omega_e \\cdot u_i + \\beta_e$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_angles_2q_ansatz(i, e, data, alphas, betas):\n",
    "    \"\"\"\n",
    "    Identify the 2 random rotation angles in a current loop, to feed into quantum circuit\n",
    "\n",
    "    :param int i: index specifying datapoint\n",
    "    :param int e: index specifying episode\n",
    "    :param array alphas: pre-generated array containing random parameters for the linear transformation\n",
    "    :param array betas: pre-generated array containing random parameters for the bias vector\n",
    "    :param array data: input data with shape (n, m) where n = no. of datapoints, and each datapoint is an m-dimensional\n",
    "        column vector\n",
    "    :return: 2-dimensional array containing the random rotation angles (numpy array)\n",
    "    \"\"\"\n",
    "    # identify the dimension of the feature space\n",
    "    dim = data.shape[1]\n",
    "    # structure the linear transformation matrix omega_e according to a 2-qubit ansatz (block diagonal format)\n",
    "    en = dim * e\n",
    "    omega_e = np.block(\n",
    "        [[alphas[en:en + dim // 2], np.zeros(dim // 2)], [np.zeros(dim // 2), alphas[en + dim // 2:en + dim]]])\n",
    "    # obtain the bias vector\n",
    "    beta_e = betas[e]\n",
    "    # perform random affine transformation on datapoint to obtain rotation angles\n",
    "    theta_ie = omega_e.dot(data[i]) + beta_e\n",
    "    return theta_ie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the rotation angles, we can use it in the circuit of the 2q ansatz. For every datapoint, we run the circuit for several shots, concatenating the bit-strings we sample into a single feature vector. This entire procedure has now transformed each of our original 2-dimensional datapoints into a high-dimensional vector composed of the bit-characters `0` and `1`. Those feature vectors can later be used in a run-of-the-mill (classical) machine learning classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete this procedure, we'll write a function that takes as input a quantum resource, and a dataset, and transforms the entire dataset into the binary vectors described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_data_2q_ansatz(qc, data, num_episodes=500):\n",
    "    \"\"\"\n",
    "    Convert input dataset into a set of binary vectors according to the 2-qubit ansatz;\n",
    "    Draws all random parameters once, and uses them for each datapoint\n",
    "\n",
    "    :param array data: input data with shape (n, m) where n = no. of datapoints, and each datapoint\n",
    "        is an m-dimensional column vector\n",
    "    :param int num_episodes: number of episodes per data point\n",
    "    :return: a high-dimensional random featurized dataset with shape (n, 2 * num_episodes), where\n",
    "        n = no. of datapoints in input data (numpy array)\n",
    "    \"\"\"\n",
    "    assert len(data.shape) == 2\n",
    "    # sample the random elements to use across all datapoints\n",
    "    alphas, betas = random_parameters_2q_ansatz(dim_input=data.shape[1], num_episodes=num_episodes)\n",
    "    # create and compile parametric circuit for the 2q ansatz\n",
    "    prog = circuit_qc_2q()\n",
    "    nq_prog = qc.compiler.quil_to_native_quil(prog)\n",
    "    executable = qc.compiler.native_quil_to_executable(nq_prog)\n",
    "    # initialize empty list to hold 'random' features for each datapoint\n",
    "    r_feats = []\n",
    "    for i in range(data.shape[0]):\n",
    "        print(f\"\\rWorking on datapoint {i+1} / {data.shape[0]}\", end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        # create random features for current datapoint\n",
    "        r_feat = []\n",
    "        for e in range(num_episodes):\n",
    "            # identify the rotation angles\n",
    "            theta_ie = rotation_angles_2q_ansatz(i, e, data, alphas, betas)\n",
    "            # collect result for current value of rotation angles\n",
    "            result = qc.run(executable, memory_map={'theta0': [theta_ie[0]], 'theta1': [theta_ie[1]]})\n",
    "            r_feat += list(result)\n",
    "        # collect together the random features for each datapoint\n",
    "        r_feats.append(r_feat)\n",
    "\n",
    "    return np.array(r_feats).reshape(data.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to featurize all the datapoints in the \"picture frames\" dataset (NOTE: the labels are not part of the input to the function we wrote above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = get_qc('2q-qvm')\n",
    "qks_feats = featurize_data_2q_ansatz(qc, picture_frames[:, :2], num_episodes=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created the randomized features using the quantum kitchen sinks procedure (the \"qks features\" for short), we can now perform another train/test split of the picture frames dataset using these new set of features along with the original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "feat_train, feat_test, label_train, label_test = train_test_split(\n",
    "            qks_feats, picture_frames[:, 2], test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit a vanilla linear classifier, such as Logistic Regression, to our qks features and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit a Logistic Regression model onto this data\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(feat_train, label_train)\n",
    "label_preds = model.predict(feat_test)\n",
    "\n",
    "# report the accuracy score obtained (on a scale of 0.0 - 1.0)\n",
    "# (see https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score)\n",
    "accuracy = accuracy_score(label_test, label_preds)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a higher accuracy score using the qks features than we did with the original features! Transforming to this high-dimensional binary vector space makes it easier for linear classifiers to classify the original dataset. Try increasing the `num_episodes` input, and see if you get even higher accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
